{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0e0cca-31a7-41fe-9ab9-71649a4a84e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minasonbol/Documents/study/deep-pod/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/minasonbol/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "import replicate\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import AuthenticationException, ConnectionError\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from utils import search_podcasts\n",
    "from ingest import create_index, download_podcast, transcribe_podcast, encode_podcast, index_podcast\n",
    "from rag import rag, search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbb21c-d525-4330-82f4-2c6aa75c3e48",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e29d4a6-61d2-40a7-a3f3-629ce13eb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_session(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        session_state[k] = v\n",
    "\n",
    "def text_input(input_text):\n",
    "    return input(input_text)\n",
    "\n",
    "def choose_podcast_option(episode_option):\n",
    "    update_session(episode_option_selected=False)\n",
    "    if episode_option == \"1. Try a sample\":\n",
    "        update_session(episode_option_selected=True, episode_option=episode_option)\n",
    "    elif episode_option == \"2. Provide the iTunes URL for a specific podcast episode\":\n",
    "        episode_url = text_input(\"Enter the iTunes URL of the episode you want:\")\n",
    "        update_session(episode_option_selected=True, episode_option=episode_option, episode_url=episode_url)\n",
    "    elif episode_option == \"3. Provide a name of a podcast to explore its most recent episode\":\n",
    "        term = text_input(\"Enter a search term for podcasts:\")\n",
    "        try:\n",
    "            if term != '':\n",
    "                found_podcasts = search_podcasts(term)\n",
    "                if found_podcasts['status'] == 'Fail':\n",
    "                    raise Exception\n",
    "                else:\n",
    "                    podcast_names = [f\"{podcast['collectionName']} by {podcast['artistName']}\" for podcast in found_podcasts['podcasts']]\n",
    "                    selected_podcast = selectbox(\"Select a podcast:\", podcast_names)\n",
    "                    selected_index=podcast_names.index(selected_podcast)\n",
    "                    update_session(episode_option_selected=True, episode_option=episode_option, found_podcasts=found_podcasts['podcasts'], selected_index=selected_index)\n",
    "        except Exception:\n",
    "            print(\"Please enter a valid search term.\")\n",
    "\n",
    "def choose_encoder(sentence_encoder):\n",
    "    update_session(sentence_encoder_selected=False)\n",
    "    if sentence_encoder == \"1. T5\":\n",
    "        encoder=SentenceTransformer(\"sentence-transformers/sentence-t5-base\")\n",
    "        update_session(sentence_encoder_selected=True, sentence_encoder=sentence_encoder, encoder=encoder)\n",
    "    elif sentence_encoder == \"2. OpenAI\":\n",
    "        embedding_model = \"text-embedding-3-large\"\n",
    "        openai_api_key = text_input(\"OpenAI API Key\", key=\"file_oa_api_key\", type=\"password\")\n",
    "        if openai_api_key != '':\n",
    "            try:\n",
    "                oa_embedding_client = OpenAI(api_key=openai_api_key)\n",
    "                response = oa_embedding_client.models.list()\n",
    "                update_session(sentence_encoder_selected=True, sentence_encoder=sentence_encoder, embedding_client=oa_embedding_client, embedding_model=embedding_model)\n",
    "            except:\n",
    "                print(\"Invalid API key. Please provide a valid API token.\")\n",
    "\n",
    "def choose_transcription_method(transcription_method, session_state):\n",
    "    if session_state.get('episode_option', False):\n",
    "        if session_state['episode_option'] != \"1. Try a sample\":\n",
    "            update_session(transcription_method_selected=False)\n",
    "            if transcription_method==\"1. Replicate\":\n",
    "                replicate_api_key = os.getenv('REPLICATE_API_KEY')\n",
    "                if replicate_api_key != '':\n",
    "                    try:\n",
    "                        replicate_client = replicate.Client(api_token=replicate_api_key)\n",
    "                        response = replicate_client.models.list()\n",
    "                        update_session(transcription_method_selected=True, transcription_method=transcription_method, transcription_client=replicate_client)\n",
    "                    except:\n",
    "                        print(\"Invalid API key. Please provide a valid API token.\")\n",
    "            elif transcription_method==\"2. Local transcription\":\n",
    "                update_session(transcription_method_selected=True, transcription_method=transcription_method)\n",
    "        else:\n",
    "            print(\"The sample podcast doesn't require a transcription method.\")\n",
    "            update_session(transcription_method_selected=True)\n",
    "\n",
    "def choose_vector_db(vector_db):\n",
    "    update_session(index_name=\"podcast-transcriber\", vector_db_selected=False)\n",
    "    if vector_db==\"1. Minsearch\":\n",
    "        update_session(vector_db=vector_db)\n",
    "        update_session(index=create_index(**session_state))\n",
    "        update_session(vector_db_selected=True, index_created=True)\n",
    "        print(f\"Index {session_state['index'].index_name} was created successfully.\")\n",
    "    elif vector_db==\"2. Elasticsearch\":\n",
    "        elasticsearch_api_key = os.getenv('ES_API_KEY')\n",
    "        elasticsearch_cloud_id = os.getenv('ES_CLOUD_ID')\n",
    "        if elasticsearch_api_key != '' and elasticsearch_cloud_id != '':\n",
    "            try:\n",
    "                es_client = Elasticsearch(cloud_id=elasticsearch_cloud_id, api_key=elasticsearch_api_key)\n",
    "                response = es_client.cluster.health()\n",
    "                update_session(vector_db=vector_db, vector_db_client=es_client)\n",
    "                update_session(index=create_index(**session_state))\n",
    "                update_session(vector_db_selected=True, index_created=True)\n",
    "                print(f\"Index {[k for k,v in session_state['index'].items()][0]} was created successfully.\")\n",
    "            except AuthenticationException:\n",
    "                print(\"Invalid API key or Cloud ID. Please provide a valid tokens.\")\n",
    "            except ConnectionError:\n",
    "                print(\"Connection error. Could not connect to the cluster.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "    elif vector_db==\"3. ChromaDB\":\n",
    "        chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        update_session(vector_db=vector_db, vector_db_client=chroma_client)\n",
    "        update_session(index=create_index(**session_state))\n",
    "        update_session(vector_db_selected=True, index_created=True)\n",
    "        print(f\"Index {session_state['vector_db_client'].list_collections()[0].name} was created successfully.\")\n",
    "\n",
    "def choose_llm(llm_option):\n",
    "    update_session(llm_option_selected=False)\n",
    "    if llm_option == \"1. GPT-4o\":\n",
    "        if session_state['sentence_encoder'] != \"2. OpenAI\":\n",
    "            openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "            if openai_api_key != '':\n",
    "                try:\n",
    "                    oa_client = OpenAI(api_key=openai_api_key)\n",
    "                    response = oa_client.models.list()\n",
    "                    update_session(llm_option_selected=True, llm_option=llm_option, llm_client=oa_client)\n",
    "                except:\n",
    "                    print(\"Invalid API key. Please provide a valid API token.\")\n",
    "        else:\n",
    "            oa_client = session_state['embedding_client']\n",
    "            update_session(llm_option_selected=True, llm_option=llm_option, llm_client=oa_client)\n",
    "\n",
    "    elif llm_option == \"2. FLAN-5\":\n",
    "        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "        update_session(llm_option_selected=True, llm_option=llm_option, llm_client=model, llm_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec40a97-cdf7-45b1-8c32-c56e1ffa282b",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c60958-eddf-4a73-9137-1fa5dd0fd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = defaultdict(\n",
    "    episode_option = \"1. Try a sample\",\n",
    "    sentence_encoder = \"1. T5\",\n",
    "    transcription_method = \"1. Replicate\",\n",
    "    vector_db = \"1. Minsearch\",\n",
    "    llm_option = \"1. GPT-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344bd2cb-79fa-482a-b9db-d16aec460049",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_podcast_option(session_state['episode_option'])\n",
    "# https://podcasts.apple.com/us/podcast/what-if-the-russian-revolution-hadnt-been-bolshevik/id1682047968?i=1000668755545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ddc5b3-ca52-4b50-bb4e-5f3f1df9eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minasonbol/Documents/study/deep-pod/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "choose_encoder(session_state['sentence_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7c5ad1-96af-4949-befb-ac55b0ca1fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample podcast doesn't require a transcription method.\n"
     ]
    }
   ],
   "source": [
    "choose_transcription_method(session_state['transcription_method'], session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4e9789-6e85-4dee-a656-fd93ca787fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index podcast-transcriber was created successfully.\n"
     ]
    }
   ],
   "source": [
    "choose_vector_db(session_state['vector_db'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1132a988-51ea-49b4-bc19-3bc43795d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_llm(session_state['llm_option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5763c86-2422-4095-a46a-7b424c493354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = 'transcription_data.json'\n",
    "\n",
    "# Open the JSON file and load the data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf74534-a2f0-41bd-84ff-501ce6e6e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    for i, chunk in enumerate(d['chunks']):\n",
    "        chunk.update({'id': str(i+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6b5deb-6961-49d8-8276-d1289d877148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "document_lengths = []\n",
    "indexing_speeds = []\n",
    "\n",
    "for d in data:\n",
    "    session_state['episode_details'] = d\n",
    "    document_lengths.append(len(d['text'].split(\" \")))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    index_podcast(**session_state)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    # print(f\"Time to run the command: {execution_time} seconds\")\n",
    "    indexing_speeds.append(execution_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f854158a-f8e5-450a-b400-dc26fe208100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1551, 164, 1322, 893, 429, 234, 658, 961, 971, 299]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5568e57-7c13-4d23-842e-2fcbde7ace5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011478662490844727,\n",
       " 0.0019309520721435547,\n",
       " 0.0036063194274902344,\n",
       " 0.0029125213623046875,\n",
       " 0.002921581268310547,\n",
       " 0.002198934555053711,\n",
       " 0.0060307979583740234,\n",
       " 0.0026946067810058594,\n",
       " 0.0028536319732666016,\n",
       " 0.0020461082458496094]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb51926-1ed0-4f2f-b0cc-bde07e3fe9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
