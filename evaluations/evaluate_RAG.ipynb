{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b85115-1df1-47d0-aa6d-494cea84395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minasonbol/Documents/study/deep-pod/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/minasonbol/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "import replicate\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import AuthenticationException, ConnectionError\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from utils import search_podcasts\n",
    "from ingest import create_index, download_podcast, transcribe_podcast, encode_podcast, index_podcast\n",
    "from rag import rag, search, llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9dc85-722e-4d96-bd5b-cafa93e7e98a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e216f8c-8aca-4017-a533-a9b0605d2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_session(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        session_state[k] = v\n",
    "\n",
    "def text_input(input_text):\n",
    "    return input(input_text)\n",
    "\n",
    "def choose_podcast_option(episode_option):\n",
    "    update_session(episode_option_selected=False)\n",
    "    if episode_option == \"1. Try a sample\":\n",
    "        update_session(episode_option_selected=True, episode_option=episode_option)\n",
    "    elif episode_option == \"2. Provide the iTunes URL for a specific podcast episode\":\n",
    "        episode_url = text_input(\"Enter the iTunes URL of the episode you want:\")\n",
    "        update_session(episode_option_selected=True, episode_option=episode_option, episode_url=episode_url)\n",
    "    elif episode_option == \"3. Provide a name of a podcast to explore its most recent episode\":\n",
    "        term = text_input(\"Enter a search term for podcasts:\")\n",
    "        try:\n",
    "            if term != '':\n",
    "                found_podcasts = search_podcasts(term)\n",
    "                if found_podcasts['status'] == 'Fail':\n",
    "                    raise Exception\n",
    "                else:\n",
    "                    podcast_names = [f\"{podcast['collectionName']} by {podcast['artistName']}\" for podcast in found_podcasts['podcasts']]\n",
    "                    selected_podcast = selectbox(\"Select a podcast:\", podcast_names)\n",
    "                    selected_index=podcast_names.index(selected_podcast)\n",
    "                    update_session(episode_option_selected=True, episode_option=episode_option, found_podcasts=found_podcasts['podcasts'], selected_index=selected_index)\n",
    "        except Exception:\n",
    "            print(\"Please enter a valid search term.\")\n",
    "\n",
    "def choose_encoder(sentence_encoder):\n",
    "    update_session(sentence_encoder_selected=False)\n",
    "    if sentence_encoder == \"1. T5\":\n",
    "        encoder=SentenceTransformer(\"sentence-transformers/sentence-t5-base\")\n",
    "        update_session(sentence_encoder_selected=True, sentence_encoder=sentence_encoder, encoder=encoder)\n",
    "    elif sentence_encoder == \"2. OpenAI\":\n",
    "        embedding_model = \"text-embedding-3-large\"\n",
    "        openai_api_key = text_input(\"OpenAI API Key\", key=\"file_oa_api_key\", type=\"password\")\n",
    "        if openai_api_key != '':\n",
    "            try:\n",
    "                oa_embedding_client = OpenAI(api_key=openai_api_key)\n",
    "                response = oa_embedding_client.models.list()\n",
    "                update_session(sentence_encoder_selected=True, sentence_encoder=sentence_encoder, embedding_client=oa_embedding_client, embedding_model=embedding_model)\n",
    "            except:\n",
    "                print(\"Invalid API key. Please provide a valid API token.\")\n",
    "\n",
    "def choose_transcription_method(transcription_method, session_state):\n",
    "    if session_state.get('episode_option', False):\n",
    "        if session_state['episode_option'] != \"1. Try a sample\":\n",
    "            update_session(transcription_method_selected=False)\n",
    "            if transcription_method==\"1. Replicate\":\n",
    "                replicate_api_key = os.getenv('REPLICATE_API_KEY')\n",
    "                if replicate_api_key != '':\n",
    "                    try:\n",
    "                        replicate_client = replicate.Client(api_token=replicate_api_key)\n",
    "                        response = replicate_client.models.list()\n",
    "                        update_session(transcription_method_selected=True, transcription_method=transcription_method, transcription_client=replicate_client)\n",
    "                    except:\n",
    "                        print(\"Invalid API key. Please provide a valid API token.\")\n",
    "            elif transcription_method==\"2. Local transcription\":\n",
    "                update_session(transcription_method_selected=True, transcription_method=transcription_method)\n",
    "        else:\n",
    "            print(\"The sample podcast doesn't require a transcription method.\")\n",
    "            update_session(transcription_method_selected=True)\n",
    "\n",
    "def choose_vector_db(vector_db):\n",
    "    update_session(index_name=\"podcast-transcriber\", vector_db_selected=False)\n",
    "    if vector_db==\"1. Minsearch\":\n",
    "        update_session(vector_db=vector_db)\n",
    "        update_session(index=create_index(**session_state))\n",
    "        update_session(vector_db_selected=True, index_created=True)\n",
    "        print(f\"Index {session_state['index'].index_name} was created successfully.\")\n",
    "    elif vector_db==\"2. Elasticsearch\":\n",
    "        elasticsearch_api_key = os.getenv('ES_API_KEY')\n",
    "        elasticsearch_cloud_id = os.getenv('ES_CLOUD_ID')\n",
    "        if elasticsearch_api_key != '' and elasticsearch_cloud_id != '':\n",
    "            try:\n",
    "                es_client = Elasticsearch(cloud_id=elasticsearch_cloud_id, api_key=elasticsearch_api_key)\n",
    "                response = es_client.cluster.health()\n",
    "                update_session(vector_db=vector_db, vector_db_client=es_client)\n",
    "                update_session(index=create_index(**session_state))\n",
    "                update_session(vector_db_selected=True, index_created=True)\n",
    "                print(f\"Index {[k for k,v in session_state['index'].items()][0]} was created successfully.\")\n",
    "            except AuthenticationException:\n",
    "                print(\"Invalid API key or Cloud ID. Please provide a valid tokens.\")\n",
    "            except ConnectionError:\n",
    "                print(\"Connection error. Could not connect to the cluster.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "    elif vector_db==\"3. ChromaDB\":\n",
    "        chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        update_session(vector_db=vector_db, vector_db_client=chroma_client)\n",
    "        update_session(index=create_index(**session_state))\n",
    "        update_session(vector_db_selected=True, index_created=True)\n",
    "        print(f\"Index {session_state['vector_db_client'].list_collections()[0].name} was created successfully.\")\n",
    "\n",
    "def choose_llm(llm_option):\n",
    "    update_session(llm_option_selected=False)\n",
    "    if llm_option == \"1. GPT-4o\":\n",
    "        if session_state['sentence_encoder'] != \"2. OpenAI\":\n",
    "            openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "            if openai_api_key != '':\n",
    "                try:\n",
    "                    oa_client = OpenAI(api_key=openai_api_key)\n",
    "                    response = oa_client.models.list()\n",
    "                    update_session(llm_option_selected=True, llm_option=llm_option, llm_client=oa_client)\n",
    "                except:\n",
    "                    print(\"Invalid API key. Please provide a valid API token.\")\n",
    "        else:\n",
    "            oa_client = session_state['embedding_client']\n",
    "            update_session(llm_option_selected=True, llm_option=llm_option, llm_client=oa_client)\n",
    "\n",
    "    elif llm_option == \"2. FLAN-5\":\n",
    "        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "        update_session(llm_option_selected=True, llm_option=llm_option, llm_client=model, llm_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9dbd05-b7fe-46ac-bf51-a87c1307dcf9",
   "metadata": {},
   "source": [
    "# Download ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858cc938-9877-4fd8-b1bd-a92abe2183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('sample/ground-truth-retrieval.csv')\n",
    "ground_truth = ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e355e-1dfa-4832-9648-9a84cf9181a7",
   "metadata": {},
   "source": [
    "# RAG Evaluation - GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ad7165f-4c48-4c43-a02e-c68d64887047",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = defaultdict(\n",
    "    episode_option = \"1. Try a sample\",\n",
    "    sentence_encoder = \"1. T5\",\n",
    "    transcription_method = \"1. Replicate\",\n",
    "    vector_db = \"2. Elasticsearch\",\n",
    "    llm_option = \"1. GPT-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78f7e57c-c3da-436d-86b7-d4754a68b82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample podcast doesn't require a transcription method.\n",
      "Index podcast-transcriber was created successfully.\n",
      "Podcast Past Present Future downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "choose_podcast_option(session_state['episode_option'])\n",
    "choose_encoder(session_state['sentence_encoder'])\n",
    "choose_transcription_method(session_state['transcription_method'], session_state)\n",
    "choose_vector_db(session_state['vector_db'])\n",
    "choose_llm(session_state['llm_option'])\n",
    "\n",
    "# download\n",
    "episode_details = download_podcast(**session_state)\n",
    "if episode_details['status'] == 'Success':\n",
    "    print(episode_details['status_message'])\n",
    "    update_session(episode_details=episode_details, podcast_downloaded=True)\n",
    "else:\n",
    "    print(episode_details['status_message'])\n",
    "    update_session(podcast_downloaded=False)\n",
    "\n",
    "# transcribe\n",
    "if session_state['podcast_downloaded'] and not session_state.get('interaction_started', False):\n",
    "    session_state['episode_details'].update(transcribe_podcast(**session_state))\n",
    "    update_session(podcast_transcribed=True)\n",
    "\n",
    "# encode\n",
    "if session_state['podcast_transcribed'] and not session_state.get('interaction_started', False):\n",
    "    if session_state['vector_db'] != \"1. Minsearch\":\n",
    "        # try:\n",
    "        session_state['episode_details'].update(encode_podcast(**session_state))\n",
    "        update_session(podcast_embedded=True)\n",
    "        # except:\n",
    "        #     print(\"Encoding failed.\")          \n",
    "        #     update_session(podcast_embedded=False)\n",
    "    else:\n",
    "        update_session(podcast_embedded=True)\n",
    "\n",
    "# populate index\n",
    "if session_state['podcast_embedded'] and not session_state.get('interaction_started', False):\n",
    "    index_podcast(**session_state)\n",
    "    update_session(podcast_indexed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e27fd69-2e45-4030-ae19-169c06e04e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state['num_results'] = 5\n",
    "query = ground_truth[1231]['question']\n",
    "result = rag(query, **session_state)\n",
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a23b4f48-46c1-4229-b671-ead933057d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0c1a46e-9999-4af9-9d41-9960b0aefd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did the Bolsheviks view terror in their methods?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = ground_truth[1231]['question']\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03bee09c-1322-49ef-9d6a-cc34dd508b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Bolsheviks were suspected of being far too comfortable with using terror as a tactic. Terror became a hallmark of Bolshevism, serving as a byword for their methods and the threat that they posed. '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm = \"\".join(list(list(rag(question, **session_state))))\n",
    "answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5ad305e-a4af-49fa-a478-6738c4bcdf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: How did the Bolsheviks view terror in their methods?\n",
      "Generated Answer: The Bolsheviks were suspected of being far too comfortable with using terror as a tactic. Bolshevism became synonymous with terror, highlighting the extent to which they were associated with this method. \n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_llm = \"\".join(list(result))\n",
    "\n",
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "825aec67-cf58-466b-a4bf-cbb59e0c8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.DataFrame(ground_truth)\n",
    "df_sample = df_question.sample(n=200, random_state=1)\n",
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe8801ca-1266-47de-8131-2a38377275ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer directly addresses the question by explaining why coherence in the ideological platform was significant for the Russian revolution. It highlights how a unified set of ideas and goals was essential for organizing and mobilizing revolutionary forces, which is a key aspect of the importance of coherence in such a context.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample[:1]):\n",
    "    question = record['question']\n",
    "    answer_llm = \"\".join(list(list(rag(question, **session_state))))\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt, **session_state)\n",
    "    print(evaluation)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5505abea-409a-4c35-8009-a9b4872f94ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [17:11<00:00,  5.16s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = \"\".join(list(list(rag(question, **session_state))))\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt, **session_state)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c2cab7-7599-4fce-b6a8-30427ab45f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628674f2-25e0-4646-bcb6-02ff89157da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "PARTLY_RELEVANT    0.545\n",
       "RELEVANT           0.360\n",
       "NON_RELEVANT       0.095\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1b6a8-2a52-4828-8b66-d5657ea672b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c1ef83-ace6-4a5a-8d44-4c76cffb376e",
   "metadata": {},
   "source": [
    "# RAG Evaluation - FLAN-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aea7d5da-4a38-47a4-85da-2d8ad734a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = defaultdict(\n",
    "    episode_option = \"1. Try a sample\",\n",
    "    sentence_encoder = \"1. T5\",\n",
    "    transcription_method = \"1. Replicate\",\n",
    "    vector_db = \"2. Elasticsearch\",\n",
    "    llm_option = \"2. FLAN-5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f67a7fbb-458e-468c-ab3c-2330f1c0d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minasonbol/Documents/study/deep-pod/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample podcast doesn't require a transcription method.\n",
      "Index podcast-transcriber was created successfully.\n",
      "Podcast Past Present Future downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "choose_podcast_option(session_state['episode_option'])\n",
    "choose_encoder(session_state['sentence_encoder'])\n",
    "choose_transcription_method(session_state['transcription_method'], session_state)\n",
    "choose_vector_db(session_state['vector_db'])\n",
    "choose_llm(session_state['llm_option'])\n",
    "\n",
    "# download\n",
    "episode_details = download_podcast(**session_state)\n",
    "if episode_details['status'] == 'Success':\n",
    "    print(episode_details['status_message'])\n",
    "    update_session(episode_details=episode_details, podcast_downloaded=True)\n",
    "else:\n",
    "    print(episode_details['status_message'])\n",
    "    update_session(podcast_downloaded=False)\n",
    "\n",
    "# transcribe\n",
    "if session_state['podcast_downloaded'] and not session_state.get('interaction_started', False):\n",
    "    session_state['episode_details'].update(transcribe_podcast(**session_state))\n",
    "    update_session(podcast_transcribed=True)\n",
    "\n",
    "# encode\n",
    "if session_state['podcast_transcribed'] and not session_state.get('interaction_started', False):\n",
    "    if session_state['vector_db'] != \"1. Minsearch\":\n",
    "        # try:\n",
    "        session_state['episode_details'].update(encode_podcast(**session_state))\n",
    "        update_session(podcast_embedded=True)\n",
    "        # except:\n",
    "        #     print(\"Encoding failed.\")          \n",
    "        #     update_session(podcast_embedded=False)\n",
    "    else:\n",
    "        update_session(podcast_embedded=True)\n",
    "\n",
    "# populate index\n",
    "if session_state['podcast_embedded'] and not session_state.get('interaction_started', False):\n",
    "    index_podcast(**session_state)\n",
    "    update_session(podcast_indexed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb7d47b4-a9a7-4b30-a0df-1c68f6caa30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state['num_results'] = 5\n",
    "query = ground_truth[1231]['question']\n",
    "result = rag(query, **session_state)\n",
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8faea87a-1725-4f89-bef1-3efb0dfd79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78de5421-bb47-4453-8b9b-673412d86b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did the Bolsheviks view terror in their methods?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = ground_truth[1231]['question']\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b40e53f-b7bc-45cf-9473-da0bf39d96fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'far too comfortable with terror as a tactic '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm = \"\".join(list(list(rag(question, **session_state))))\n",
    "answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a602158-ab0d-426a-92bd-08adee6cf989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: How did the Bolsheviks view terror in their methods?\n",
      "Generated Answer: far too comfortable with terror as a tactic \n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_llm = \"\".join(list(result))\n",
    "\n",
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52f395c5-7db9-4dfc-b987-24cd27081d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [1:41:56<00:00, 30.58s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = \"\".join(list(list(rag(question, **session_state))))\n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt, **session_state)\n",
    "    # evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10ce8272-fca3-42ad-9b32-8e9fac44e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "df_eval['relevance'] = df_eval['evaluation']\n",
    "# df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "# df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43c67389-326a-41f1-8962-0928a936c9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "PARTLY_RELEVANT    0.61\n",
       "NON_RELEVANT       0.39\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ddea73-548e-4e09-90e2-fb9181337bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92057d2b-2656-4dde-a6c6-eb9ac06d2c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe0317-4930-46b0-99ec-0dbbd0171e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abc484a5-4f22-49c2-a9e8-caa40bba1d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9c319b45ab9f4d89bcedc7e31cf6f973.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9c319b45ab9f4d89bcedc7e31cf6f973.vega-embed details,\n",
       "  #altair-viz-9c319b45ab9f4d89bcedc7e31cf6f973.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9c319b45ab9f4d89bcedc7e31cf6f973\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9c319b45ab9f4d89bcedc7e31cf6f973\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9c319b45ab9f4d89bcedc7e31cf6f973\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-efe9a181e2e72eb2f1aafb2b16f5d645\"}, \"facet\": {\"field\": \"metric\", \"header\": {\"labelAngle\": 0}, \"title\": \"Metric\", \"type\": \"nominal\"}, \"spec\": {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": \"System\", \"type\": \"nominal\"}, \"x\": {\"field\": \"system\", \"title\": \"System\", \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"Value\", \"type\": \"quantitative\"}}}, \"columns\": 3, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"title\": \"Comparison of Metrics for ChromaDB, Minsearch, and Elasticsearch\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-efe9a181e2e72eb2f1aafb2b16f5d645\": [{\"system\": \"ChromaDB\", \"metric\": \"hit_rate\", \"value\": 0.7024208566108008}, {\"system\": \"ChromaDB\", \"metric\": \"mrr\", \"value\": 0.29600869025450816}, {\"system\": \"ChromaDB\", \"metric\": \"average_retrieval_time\", \"value\": 0.022532762051516626}, {\"system\": \"Minsearch\", \"metric\": \"hit_rate\", \"value\": 0.7169459962756052}, {\"system\": \"Minsearch\", \"metric\": \"mrr\", \"value\": 0.5400331057314296}, {\"system\": \"Minsearch\", \"metric\": \"average_retrieval_time\", \"value\": 0.005704473250405083}, {\"system\": \"Elasticsearch\", \"metric\": \"hit_rate\", \"value\": 0.7415270018621974}, {\"system\": \"Elasticsearch\", \"metric\": \"mrr\", \"value\": 0.6090006207324642}, {\"system\": \"Elasticsearch\", \"metric\": \"average_retrieval_time\", \"value\": 0.08933900712366655}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Define the metrics for each search engine\n",
    "data = {\n",
    "    'system': ['ChromaDB', 'ChromaDB', 'ChromaDB',\n",
    "               'Minsearch', 'Minsearch', 'Minsearch',\n",
    "               'Elasticsearch', 'Elasticsearch', 'Elasticsearch'],\n",
    "    'metric': ['hit_rate', 'mrr', 'average_retrieval_time',\n",
    "               'hit_rate', 'mrr', 'average_retrieval_time',\n",
    "               'hit_rate', 'mrr', 'average_retrieval_time'],\n",
    "    'value': [0.7024208566108008, 0.29600869025450816, 0.022532762051516626,\n",
    "              0.7169459962756052, 0.5400331057314296, 0.005704473250405083,\n",
    "              0.7415270018621974, 0.6090006207324642, 0.08933900712366655]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the Altair plot with different y-axis titles based on the metric\n",
    "chart = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('system:N', title='System'),\n",
    "    y=alt.Y('value:Q', title='Value', scale=alt.Scale(zero=False)),\n",
    "    color=alt.Color('system:N', title='System')\n",
    ").facet(\n",
    "    facet=alt.Facet('metric:N', title='Metric', header=alt.Header(labelAngle=0)),\n",
    "    columns=3\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ").properties(\n",
    "    title='Comparison of Metrics for ChromaDB, Minsearch, and Elasticsearch'\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfefc95d-4ab3-43ec-809d-bc3cab10648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-0fc8279b0837470fbb599448e62b549d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-0fc8279b0837470fbb599448e62b549d.vega-embed details,\n",
       "  #altair-viz-0fc8279b0837470fbb599448e62b549d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-0fc8279b0837470fbb599448e62b549d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0fc8279b0837470fbb599448e62b549d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0fc8279b0837470fbb599448e62b549d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-efe9a181e2e72eb2f1aafb2b16f5d645\"}, \"facet\": {\"field\": \"metric\", \"header\": {\"labelAngle\": 0}, \"title\": \"Metric\", \"type\": \"nominal\"}, \"spec\": {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"Value\", \"type\": \"quantitative\"}}}, \"columns\": 3, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"title\": \"Comparison of Metrics for ChromaDB, Minsearch, and Elasticsearch\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-efe9a181e2e72eb2f1aafb2b16f5d645\": [{\"system\": \"ChromaDB\", \"metric\": \"hit_rate\", \"value\": 0.7024208566108008}, {\"system\": \"ChromaDB\", \"metric\": \"mrr\", \"value\": 0.29600869025450816}, {\"system\": \"ChromaDB\", \"metric\": \"average_retrieval_time\", \"value\": 0.022532762051516626}, {\"system\": \"Minsearch\", \"metric\": \"hit_rate\", \"value\": 0.7169459962756052}, {\"system\": \"Minsearch\", \"metric\": \"mrr\", \"value\": 0.5400331057314296}, {\"system\": \"Minsearch\", \"metric\": \"average_retrieval_time\", \"value\": 0.005704473250405083}, {\"system\": \"Elasticsearch\", \"metric\": \"hit_rate\", \"value\": 0.7415270018621974}, {\"system\": \"Elasticsearch\", \"metric\": \"mrr\", \"value\": 0.6090006207324642}, {\"system\": \"Elasticsearch\", \"metric\": \"average_retrieval_time\", \"value\": 0.08933900712366655}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Define the metrics for each search engine\n",
    "data = {\n",
    "    'system': ['ChromaDB', 'ChromaDB', 'ChromaDB',\n",
    "               'Minsearch', 'Minsearch', 'Minsearch',\n",
    "               'Elasticsearch', 'Elasticsearch', 'Elasticsearch'],\n",
    "    'metric': ['hit_rate', 'mrr', 'average_retrieval_time',\n",
    "               'hit_rate', 'mrr', 'average_retrieval_time',\n",
    "               'hit_rate', 'mrr', 'average_retrieval_time'],\n",
    "    'value': [0.7024208566108008, 0.29600869025450816, 0.022532762051516626,\n",
    "              0.7169459962756052, 0.5400331057314296, 0.005704473250405083,\n",
    "              0.7415270018621974, 0.6090006207324642, 0.08933900712366655]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the Altair plot with different y-axis titles based on the metric\n",
    "chart = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('system:N', title=None, axis=alt.Axis(labels=False, ticks=False)),\n",
    "    y=alt.Y('value:Q', title='Value', scale=alt.Scale(zero=False)),\n",
    "    color=alt.Color('system:N', title=None)\n",
    ").facet(\n",
    "    facet=alt.Facet('metric:N', title='Metric', header=alt.Header(labelAngle=0)),\n",
    "    columns=3\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ").properties(\n",
    "    title='Comparison of Metrics for ChromaDB, Minsearch, and Elasticsearch'\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6db5d7b0-b1c8-4e3b-a146-ae74e66cb54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-fda35cce21784a3db44f55ea90a7ca03.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-fda35cce21784a3db44f55ea90a7ca03.vega-embed details,\n",
       "  #altair-viz-fda35cce21784a3db44f55ea90a7ca03.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-fda35cce21784a3db44f55ea90a7ca03\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fda35cce21784a3db44f55ea90a7ca03\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fda35cce21784a3db44f55ea90a7ca03\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-91e66e120f38a42af9aac021d33d7a03\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"%\", \"type\": \"quantitative\"}}, \"title\": \"Hit Rate\", \"width\": 200}, {\"data\": {\"name\": \"data-01d9d31d5cb48166a9b9cc6e64049aaf\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"%\", \"type\": \"quantitative\"}}, \"title\": \"MRR\", \"width\": 200}, {\"data\": {\"name\": \"data-bf7ce81c3afabb4a3efb9d0285fee97a\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"Seconds\", \"type\": \"quantitative\"}}, \"title\": \"Average Retrieval Time\", \"width\": 200}], \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"title\": \"Comparison of Metrics for ChromaDB, Minsearch, and Elasticsearch\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-91e66e120f38a42af9aac021d33d7a03\": [{\"system\": \"ChromaDB\", \"metric\": \"Hit Rate\", \"value\": 0.7024208566108008}, {\"system\": \"Minsearch\", \"metric\": \"Hit Rate\", \"value\": 0.7169459962756052}, {\"system\": \"Elasticsearch\", \"metric\": \"Hit Rate\", \"value\": 0.7415270018621974}], \"data-01d9d31d5cb48166a9b9cc6e64049aaf\": [{\"system\": \"ChromaDB\", \"metric\": \"MRR\", \"value\": 0.29600869025450816}, {\"system\": \"Minsearch\", \"metric\": \"MRR\", \"value\": 0.5400331057314296}, {\"system\": \"Elasticsearch\", \"metric\": \"MRR\", \"value\": 0.6090006207324642}], \"data-bf7ce81c3afabb4a3efb9d0285fee97a\": [{\"system\": \"ChromaDB\", \"metric\": \"Average Retrieval Time\", \"value\": 0.022532762051516626}, {\"system\": \"Minsearch\", \"metric\": \"Average Retrieval Time\", \"value\": 0.005704473250405083}, {\"system\": \"Elasticsearch\", \"metric\": \"Average Retrieval Time\", \"value\": 0.08933900712366655}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Define the metrics for each search engine\n",
    "data = {\n",
    "    'system': ['ChromaDB', 'ChromaDB', 'ChromaDB',\n",
    "               'Minsearch', 'Minsearch', 'Minsearch',\n",
    "               'Elasticsearch', 'Elasticsearch', 'Elasticsearch'],\n",
    "    'metric': ['Hit Rate', 'MRR', 'Average Retrieval Time',\n",
    "               'Hit Rate', 'MRR', 'Average Retrieval Time',\n",
    "               'Hit Rate', 'MRR', 'Average Retrieval Time'],\n",
    "    'value': [0.7024208566108008, 0.29600869025450816, 0.022532762051516626,\n",
    "              0.7169459962756052, 0.5400331057314296, 0.005704473250405083,\n",
    "              0.7415270018621974, 0.6090006207324642, 0.08933900712366655]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create separate charts for each metric with appropriate y-axis titles\n",
    "charts = []\n",
    "metrics = df['metric'].unique()\n",
    "\n",
    "for metric in metrics:\n",
    "    y_title = 'Seconds' if metric == 'Average Retrieval Time' else '%'\n",
    "    chart = alt.Chart(df[df['metric'] == metric]).mark_bar().encode(\n",
    "        x=alt.X('system:N', title=None, axis=alt.Axis(labels=False, ticks=False)),\n",
    "        y=alt.Y('value:Q', title=y_title, scale=alt.Scale(zero=False)),\n",
    "        color=alt.Color('system:N', title=None)\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        title=metric\n",
    "    )\n",
    "    charts.append(chart)\n",
    "\n",
    "final_chart = alt.hconcat(*charts).resolve_scale(y='independent').properties(\n",
    "    title='Comparison of Metrics for ChromaDB, Minsearch, and Elasticsearch'\n",
    ")\n",
    "\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa2dc4-057b-4f47-8e83-5b0af67881ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e2f9a-4fb3-4c2f-b3ec-97a30ca95d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "226384b3-129f-4169-9ddc-cc7adabd7ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7db12140b8884082a3a1f1d26354ada0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7db12140b8884082a3a1f1d26354ada0.vega-embed details,\n",
       "  #altair-viz-7db12140b8884082a3a1f1d26354ada0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7db12140b8884082a3a1f1d26354ada0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7db12140b8884082a3a1f1d26354ada0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7db12140b8884082a3a1f1d26354ada0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-91e66e120f38a42af9aac021d33d7a03\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"%\", \"type\": \"quantitative\"}}, \"title\": \"Hit Rate\", \"width\": 200}, {\"data\": {\"name\": \"data-01d9d31d5cb48166a9b9cc6e64049aaf\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"%\", \"type\": \"quantitative\"}}, \"title\": \"MRR\", \"width\": 200}, {\"data\": {\"name\": \"data-bf7ce81c3afabb4a3efb9d0285fee97a\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"Seconds\", \"type\": \"quantitative\"}}, \"title\": \"Average Retrieval Time\", \"width\": 200}], \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-91e66e120f38a42af9aac021d33d7a03\": [{\"system\": \"ChromaDB\", \"metric\": \"Hit Rate\", \"value\": 0.7024208566108008}, {\"system\": \"Minsearch\", \"metric\": \"Hit Rate\", \"value\": 0.7169459962756052}, {\"system\": \"Elasticsearch\", \"metric\": \"Hit Rate\", \"value\": 0.7415270018621974}], \"data-01d9d31d5cb48166a9b9cc6e64049aaf\": [{\"system\": \"ChromaDB\", \"metric\": \"MRR\", \"value\": 0.29600869025450816}, {\"system\": \"Minsearch\", \"metric\": \"MRR\", \"value\": 0.5400331057314296}, {\"system\": \"Elasticsearch\", \"metric\": \"MRR\", \"value\": 0.6090006207324642}], \"data-bf7ce81c3afabb4a3efb9d0285fee97a\": [{\"system\": \"ChromaDB\", \"metric\": \"Average Retrieval Time\", \"value\": 0.022532762051516626}, {\"system\": \"Minsearch\", \"metric\": \"Average Retrieval Time\", \"value\": 0.005704473250405083}, {\"system\": \"Elasticsearch\", \"metric\": \"Average Retrieval Time\", \"value\": 0.08933900712366655}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Define the metrics for each search engine\n",
    "data = {\n",
    "    'system': ['ChromaDB', 'ChromaDB', 'ChromaDB',\n",
    "               'Minsearch', 'Minsearch', 'Minsearch',\n",
    "               'Elasticsearch', 'Elasticsearch', 'Elasticsearch'],\n",
    "    'metric': ['Hit Rate', 'MRR', 'Average Retrieval Time',\n",
    "               'Hit Rate', 'MRR', 'Average Retrieval Time',\n",
    "               'Hit Rate', 'MRR', 'Average Retrieval Time'],\n",
    "    'value': [0.7024208566108008, 0.29600869025450816, 0.022532762051516626,\n",
    "              0.7169459962756052, 0.5400331057314296, 0.005704473250405083,\n",
    "              0.7415270018621974, 0.6090006207324642, 0.08933900712366655]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create separate charts for each metric with appropriate y-axis titles\n",
    "charts = []\n",
    "metrics = df['metric'].unique()\n",
    "\n",
    "for metric in metrics:\n",
    "    y_title = 'Seconds' if metric == 'Average Retrieval Time' else '%'\n",
    "    chart = alt.Chart(df[df['metric'] == metric]).mark_bar().encode(\n",
    "        x=alt.X('system:N', title=None, axis=alt.Axis(labels=False, ticks=False)),\n",
    "        y=alt.Y('value:Q', title=y_title, scale=alt.Scale(zero=False)),\n",
    "        color=alt.Color('system:N', title=None)\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        title=metric\n",
    "    )\n",
    "    charts.append(chart)\n",
    "\n",
    "final_chart = alt.hconcat(*charts).resolve_scale(y='independent')\n",
    "\n",
    "final_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22f4eb39-8543-44df-b247-28c40a0e52f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d4c4eee65e9047bb9d73fea7199f5344.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d4c4eee65e9047bb9d73fea7199f5344.vega-embed details,\n",
       "  #altair-viz-d4c4eee65e9047bb9d73fea7199f5344.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d4c4eee65e9047bb9d73fea7199f5344\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d4c4eee65e9047bb9d73fea7199f5344\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d4c4eee65e9047bb9d73fea7199f5344\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-91e66e120f38a42af9aac021d33d7a03\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": true, \"ticks\": true}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"%\", \"type\": \"quantitative\"}}, \"width\": 200}, {\"data\": {\"name\": \"data-01d9d31d5cb48166a9b9cc6e64049aaf\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": true, \"ticks\": true}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"%\", \"type\": \"quantitative\"}}, \"width\": 200}, {\"data\": {\"name\": \"data-bf7ce81c3afabb4a3efb9d0285fee97a\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"system\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labels\": true, \"ticks\": true}, \"field\": \"system\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"zero\": false}, \"title\": \"Seconds\", \"type\": \"quantitative\"}}, \"width\": 200}], \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-91e66e120f38a42af9aac021d33d7a03\": [{\"system\": \"ChromaDB\", \"metric\": \"Hit Rate\", \"value\": 0.7024208566108008}, {\"system\": \"Minsearch\", \"metric\": \"Hit Rate\", \"value\": 0.7169459962756052}, {\"system\": \"Elasticsearch\", \"metric\": \"Hit Rate\", \"value\": 0.7415270018621974}], \"data-01d9d31d5cb48166a9b9cc6e64049aaf\": [{\"system\": \"ChromaDB\", \"metric\": \"MRR\", \"value\": 0.29600869025450816}, {\"system\": \"Minsearch\", \"metric\": \"MRR\", \"value\": 0.5400331057314296}, {\"system\": \"Elasticsearch\", \"metric\": \"MRR\", \"value\": 0.6090006207324642}], \"data-bf7ce81c3afabb4a3efb9d0285fee97a\": [{\"system\": \"ChromaDB\", \"metric\": \"Average Retrieval Time\", \"value\": 0.022532762051516626}, {\"system\": \"Minsearch\", \"metric\": \"Average Retrieval Time\", \"value\": 0.005704473250405083}, {\"system\": \"Elasticsearch\", \"metric\": \"Average Retrieval Time\", \"value\": 0.08933900712366655}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Define the metrics for each search engine\n",
    "data = {\n",
    "    'system': ['ChromaDB', 'ChromaDB', 'ChromaDB',\n",
    "               'Minsearch', 'Minsearch', 'Minsearch',\n",
    "               'Elasticsearch', 'Elasticsearch', 'Elasticsearch'],\n",
    "    'metric': ['Hit Rate', 'MRR', 'Average Retrieval Time',\n",
    "               'Hit Rate', 'MRR', 'Average Retrieval Time',\n",
    "               'Hit Rate', 'MRR', 'Average Retrieval Time'],\n",
    "    'value': [0.7024208566108008, 0.29600869025450816, 0.022532762051516626,\n",
    "              0.7169459962756052, 0.5400331057314296, 0.005704473250405083,\n",
    "              0.7415270018621974, 0.6090006207324642, 0.08933900712366655]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create separate charts for each metric with appropriate y-axis titles\n",
    "charts = []\n",
    "metrics = df['metric'].unique()\n",
    "\n",
    "for metric in metrics:\n",
    "    y_title = 'Seconds' if metric == 'Average Retrieval Time' else '%'\n",
    "    chart = alt.Chart(df[df['metric'] == metric]).mark_bar().encode(\n",
    "        x=alt.X('system:N', title=None, axis=alt.Axis(labels=True, ticks=True)),\n",
    "        y=alt.Y('value:Q', title=y_title, scale=alt.Scale(zero=False)),\n",
    "        color=alt.Color('system:N', legend=None)\n",
    "    ).properties(\n",
    "        width=200\n",
    "    )\n",
    "    charts.append(chart)\n",
    "\n",
    "final_chart = alt.hconcat(*charts).resolve_scale(y='independent')\n",
    "\n",
    "final_chart.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
