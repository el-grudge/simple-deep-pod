{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c836468-950e-4519-81bc-b37051ff4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/minasonbol/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "import replicate\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import AuthenticationException, ConnectionError\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from utils import search_podcasts\n",
    "from ingest import create_index, download_podcast, transcribe_podcast, encode_podcast, index_podcast\n",
    "from rag import rag, search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6cbb84-dc24-4c53-8a40-00d47e5a905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_session(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        session_state[k] = v\n",
    "\n",
    "def text_input(input_text):\n",
    "    return input(input_text)\n",
    "\n",
    "def choose_podcast_option(episode_option):\n",
    "    update_session(episode_option_selected=False)\n",
    "    if episode_option == \"1. Try a sample\":\n",
    "        update_session(episode_option_selected=True, episode_option=episode_option)\n",
    "    elif episode_option == \"2. Provide the iTunes URL for a specific podcast episode\":\n",
    "        episode_url = text_input(\"Enter the iTunes URL of the episode you want:\")\n",
    "        update_session(episode_option_selected=True, episode_option=episode_option, episode_url=episode_url)\n",
    "    elif episode_option == \"3. Provide a name of a podcast to explore its most recent episode\":\n",
    "        term = text_input(\"Enter a search term for podcasts:\")\n",
    "        try:\n",
    "            if term != '':\n",
    "                found_podcasts = search_podcasts(term)\n",
    "                if found_podcasts['status'] == 'Fail':\n",
    "                    raise Exception\n",
    "                else:\n",
    "                    podcast_names = [f\"{podcast['collectionName']} by {podcast['artistName']}\" for podcast in found_podcasts['podcasts']]\n",
    "                    selected_podcast = selectbox(\"Select a podcast:\", podcast_names)\n",
    "                    selected_index=podcast_names.index(selected_podcast)\n",
    "                    update_session(episode_option_selected=True, episode_option=episode_option, found_podcasts=found_podcasts['podcasts'], selected_index=selected_index)\n",
    "        except Exception:\n",
    "            print(\"Please enter a valid search term.\")\n",
    "\n",
    "def choose_encoder(sentence_encoder):\n",
    "    update_session(sentence_encoder_selected=False)\n",
    "    if sentence_encoder == \"1. T5\":\n",
    "        encoder=SentenceTransformer(\"sentence-transformers/sentence-t5-base\")\n",
    "        update_session(sentence_encoder_selected=True, sentence_encoder=sentence_encoder, encoder=encoder)\n",
    "    elif sentence_encoder == \"2. OpenAI\":\n",
    "        embedding_model = \"text-embedding-3-large\"\n",
    "        openai_api_key = text_input(\"OpenAI API Key\", key=\"file_oa_api_key\", type=\"password\")\n",
    "        if openai_api_key != '':\n",
    "            try:\n",
    "                oa_embedding_client = OpenAI(api_key=openai_api_key)\n",
    "                response = oa_embedding_client.models.list()\n",
    "                update_session(sentence_encoder_selected=True, sentence_encoder=sentence_encoder, embedding_client=oa_embedding_client, embedding_model=embedding_model)\n",
    "            except:\n",
    "                print(\"Invalid API key. Please provide a valid API token.\")\n",
    "\n",
    "def choose_transcription_method(transcription_method, session_state):\n",
    "    if session_state.get('episode_option', False):\n",
    "        if session_state['episode_option'] != \"1. Try a sample\":\n",
    "            update_session(transcription_method_selected=False)\n",
    "            if transcription_method==\"1. Replicate\":\n",
    "                replicate_api_key = os.getenv('REPLICATE_API_KEY')\n",
    "                if replicate_api_key != '':\n",
    "                    try:\n",
    "                        replicate_client = replicate.Client(api_token=replicate_api_key)\n",
    "                        response = replicate_client.models.list()\n",
    "                        update_session(transcription_method_selected=True, transcription_method=transcription_method, transcription_client=replicate_client)\n",
    "                    except:\n",
    "                        print(\"Invalid API key. Please provide a valid API token.\")\n",
    "            elif transcription_method==\"2. Local transcription\":\n",
    "                update_session(transcription_method_selected=True, transcription_method=transcription_method)\n",
    "        else:\n",
    "            print(\"The sample podcast doesn't require a transcription method.\")\n",
    "            update_session(transcription_method_selected=True)\n",
    "\n",
    "def choose_vector_db(vector_db):\n",
    "    update_session(index_name=\"podcast-transcriber\", vector_db_selected=False)\n",
    "    if vector_db==\"1. Minsearch\":\n",
    "        update_session(vector_db=vector_db)\n",
    "        update_session(index=create_index(**session_state))\n",
    "        update_session(vector_db_selected=True, index_created=True)\n",
    "        print(f\"Index {session_state['index'].index_name} was created successfully.\")\n",
    "    elif vector_db==\"2. Elasticsearch\":\n",
    "        elasticsearch_api_key = os.getenv('ES_API_KEY')\n",
    "        elasticsearch_cloud_id = os.getenv('ES_CLOUD_ID')\n",
    "        if elasticsearch_api_key != '' and elasticsearch_cloud_id != '':\n",
    "            try:\n",
    "                es_client = Elasticsearch(cloud_id=elasticsearch_cloud_id, api_key=elasticsearch_api_key)\n",
    "                response = es_client.cluster.health()\n",
    "                update_session(vector_db=vector_db, vector_db_client=es_client)\n",
    "                update_session(index=create_index(**session_state))\n",
    "                update_session(vector_db_selected=True, index_created=True)\n",
    "                print(f\"Index {[k for k,v in session_state['index'].items()][0]} was created successfully.\")\n",
    "            except AuthenticationException:\n",
    "                print(\"Invalid API key or Cloud ID. Please provide a valid tokens.\")\n",
    "            except ConnectionError:\n",
    "                print(\"Connection error. Could not connect to the cluster.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "    elif vector_db==\"3. ChromaDB\":\n",
    "        chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        update_session(vector_db=vector_db, vector_db_client=chroma_client)\n",
    "        update_session(index=create_index(**session_state))\n",
    "        update_session(vector_db_selected=True, index_created=True)\n",
    "        print(f\"Index {session_state['vector_db_client'].list_collections()[0].name} was created successfully.\")\n",
    "\n",
    "def choose_llm(llm_option):\n",
    "    update_session(llm_option_selected=False)\n",
    "    if llm_option == \"1. GPT-4o\":\n",
    "        if session_state['sentence_encoder'] != \"2. OpenAI\":\n",
    "            openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "            if openai_api_key != '':\n",
    "                try:\n",
    "                    oa_client = OpenAI(api_key=openai_api_key)\n",
    "                    response = oa_client.models.list()\n",
    "                    update_session(llm_option_selected=True, llm_option=llm_option, llm_client=oa_client)\n",
    "                except:\n",
    "                    print(\"Invalid API key. Please provide a valid API token.\")\n",
    "        else:\n",
    "            oa_client = session_state['embedding_client']\n",
    "            update_session(llm_option_selected=True, llm_option=llm_option, llm_client=oa_client)\n",
    "\n",
    "    elif llm_option == \"2. FLAN-5\":\n",
    "        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "        update_session(llm_option_selected=True, llm_option=llm_option, llm_client=model, llm_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae5f611-95f0-438e-baa3-c87c6328b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = defaultdict(\n",
    "    episode_option = \"1. Try a sample\",\n",
    "    sentence_encoder = \"1. T5\",\n",
    "    transcription_method = \"1. Replicate\",\n",
    "    vector_db = \"1. Minsearch\",\n",
    "    llm_option = \"1. GPT-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e20739-6498-438c-b942-4638c11a74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_podcast_option(session_state['episode_option'])\n",
    "# https://podcasts.apple.com/us/podcast/what-if-the-russian-revolution-hadnt-been-bolshevik/id1682047968?i=1000668755545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55478e61-ef60-42b8-9333-774513922875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minasonbol/Documents/study/deep-pod/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "choose_encoder(session_state['sentence_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d73753e-8e14-44cd-9944-13327029d6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample podcast doesn't require a transcription method.\n"
     ]
    }
   ],
   "source": [
    "choose_transcription_method(session_state['transcription_method'], session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de66474-8f9b-46bb-b116-68e00631eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index podcast-transcriber was created successfully.\n"
     ]
    }
   ],
   "source": [
    "choose_vector_db(session_state['vector_db'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81f30d3-1899-455c-9ff0-de0a2307f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_llm(session_state['llm_option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec146ac-8870-42aa-9c66-ce6292ddc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "episode_details = download_podcast(**session_state)\n",
    "update_session(episode_details=episode_details, podcast_downloaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699d9aa2-75d2-4bb9-8cbb-fa7ecaafa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to convert to pandas\n",
    "documents = session_state['episode_details']['chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "981a1b5f-269d-4675-bc0f-32c3cfbe14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a user of our deep-pod application.\n",
    "Formulate 5 questions this user might ask based on a provided text.\n",
    "Make the questions specific to this text.\n",
    "The record should contain the answer to the questions, and the questions should\n",
    "be complete and not too short. Use as few words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "text: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d03276-bd15-4776-9587-453579867d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07c80b8-8910-45d3-906f-86d547269067",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(**documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a52e2fb-a245-4026-b4c2-7cb1e6a99f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You emulate a user of our deep-pod application.\\nFormulate 5 questions this user might ask based on a provided text.\\nMake the questions specific to this text.\\nThe record should contain the answer to the questions, and the questions should\\nbe complete and not too short. Use as few words as possible from the record. \\n\\nThe record:\\n\\ntext:  Balancing a wellness routine and busy travel plans?\\n\\nProvide the output in parsable JSON without using code blocks:\\n\\n{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f8a180-788d-4fae-9f3f-353649fecbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461c1305-54c3-4864-a31e-a80fd8c9a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa18612-e1a9-4088-a4fc-d77f1a3a9ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['What are some tips for maintaining a wellness routine while traveling?',\n",
       "  'How can I prioritize wellness activities during a busy trip?',\n",
       "  'What challenges might I face in keeping my wellness routine while on the road?',\n",
       "  'Are there specific wellness practices that are easy to incorporate while traveling?',\n",
       "  'How can I adapt my wellness routine to fit a hectic travel schedule?']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "180bf172-695b-4e4e-8ae5-e82775072647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a484fa2-4c40-4745-af89-e9c95c7bdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12a65a29-bcbc-4c78-985f-bc2e7170dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 537/537 [13:32<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "id_iterator = itertools.count(start=1)\n",
    "for doc in tqdm(documents): \n",
    "    doc_id = str(next(id_iterator))\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions_raw = generate_questions(doc)\n",
    "    questions = json.loads(questions_raw)\n",
    "    results[doc_id] = questions['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab954d0d-6456-450c-950f-3b71b3da133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7afc2943-486a-42ec-aa2e-868828baee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.DataFrame(final_results, columns=['id', 'question'])\n",
    "ground_truth.to_csv('sample/ground-truth-retrieval.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
